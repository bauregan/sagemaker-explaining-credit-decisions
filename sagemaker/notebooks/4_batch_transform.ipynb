{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Batch Transform for Explanations\n", "\n", "In this notebook, we'll use Amazon SageMaker Batch Tranform to obtain\n", "explanations for our complete dataset.\n", "\n", "<p align=\"center\">\n", "  <img src=\"https://github.com/awslabs/sagemaker-explaining-credit-decisions/raw/master/docs/architecture_diagrams/stage_4.png\" width=\"1000px\">\n", "</p>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We start by importing a variety of packages that will be used throughout\n", "the notebook. One of the most important packages used throughout this\n", "solution is the Amazon SageMaker Python SDK (i.e. `import sagemaker`). We\n", "also import modules from our own custom package that can be found at\n", "`./package`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import boto3\n", "from pathlib import Path\n", "import sagemaker\n", "from sagemaker.transformer import Transformer\n", "\n", "from package import config, utils"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Up next, we define the current folder, a sagemaker session and a\n", "sagemaker client (from `boto3`)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["current_folder = utils.get_current_folder(globals())\n", "sagemaker_session = sagemaker.Session()\n", "sagemaker_client = boto3.client('sagemaker')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We define a function below to retrieve the same model that was created in\n", "last stage. Model refers to the package of model assets and deployment\n", "code. We could have created another model here (using the same model data\n", "from the training stage) but let's use the same model to avoid\n", "duplication."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_latest_model(name_contains):\n", "    response = sagemaker_client.list_models(\n", "        NameContains=name_contains\n", "    )\n", "    models = response['Models']\n", "    assert len(models) > 0, \"Couldn't find any models with '{}' in name.\".format(name_contains)\n", "    latest_model = models[0]['ModelName']\n", "    return latest_model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["latest_model = get_latest_model(config.STACK_NAME)\n", "job_name = latest_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Unlike the last stage, where we deployed an endpoint, we define a\n", "`Transformer` to perform the batch computation. We specify the instance\n", "type that should be used for the computation (i.e. `ml.c5.xlarge`) and a\n", "number of other parameters. `strategy='SingleRecord'` means that records\n", "will be processed by the explainer one at a time. And `output_path`\n", "defines where the Batch Transform output should be saved."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["batch_explainer = Transformer(\n", "    model_name=latest_model,\n", "    instance_count=1,\n", "    instance_type='ml.c5.xlarge',\n", "    strategy='SingleRecord',\n", "    assemble_with='Line',\n", "    output_path='s3://' + str(Path(config.S3_BUCKET, 'explanations', job_name)) + '/',\n", "    accept='application/json',\n", "    base_transform_job_name=latest_model,\n", "    sagemaker_session=sagemaker_session\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We haven't yet started the Batch Tranform Job. Calling `.transform` does\n", "that below. We also specify the `content_type` at this stage, which gives\n", "us control over what type of entities we want to return from the\n", "explainer. As an example, we have requested SHAP interaction values\n", "during this batch job."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["entities = [\n", "    'data',\n", "    'features',\n", "    'prediction',\n", "    'explanation_shap_values',\n", "    'explanation_shap_interaction_values'\n", "]\n", "batch_explainer.transform(\n", "    data='s3://' + str(Path(config.S3_BUCKET, config.DATASETS_S3_PREFIX, 'data_test')) + '/',\n", "    content_type=\"application/json; entities={}\".format(\",\".join(entities)),\n", "    split_type='Line',\n", "    wait=True\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After the Batch Transform Job has completed successfully, we will have a\n", "complete set of explanations sitting in the Amazon S3 bucket."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Next Stage\n", "\n", "Up next we'll develop a dashboard for this batch of explanations using\n", "Amazon SageMaker and Streamlit.\n", "\n", "[Click here to continue.](./5_dashboard.ipynb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}, "kernelspec": {"display_name": "conda_python3", "language": "python", "name": "conda_python3"}}, "nbformat": 4, "nbformat_minor": 4}